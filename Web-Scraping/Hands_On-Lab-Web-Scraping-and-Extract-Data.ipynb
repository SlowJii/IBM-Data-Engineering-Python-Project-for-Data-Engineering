{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Chúng ta sẽ thảo luận về giao thức HTTP sử dụng thư viện Requests, một phương pháp phổ biến để xử lý giao thức HTTP trong Python. Chúng ta sẽ xem xét:\n",
    "\n",
    "- Tổng quan về thư viện Requests của Python để làm việc với giao thức HTTP.\n",
    "- Giới thiệu về các yêu cầu GET và POST.\n",
    "\n",
    "#### Thư viện Requests:\n",
    "Requests là một thư viện Python cho phép bạn dễ dàng gửi các yêu cầu HTTP/1.1. Bạn có thể import thư viện như sau:\n",
    "```python\n",
    "import requests\n",
    "```\n",
    "\n",
    "#### Ví dụ về yêu cầu GET:\n",
    "Bạn có thể thực hiện một yêu cầu GET đến `www.ibm.com` như sau:\n",
    "```python\n",
    "response = requests.get('https://www.ibm.com')\n",
    "print(response.status_code)  # In ra mã trạng thái (200 cho OK)\n",
    "```\n",
    "- Sử dụng `response.headers` để xem tiêu đề phản hồi.\n",
    "- Sử dụng `response.text` để hiển thị nội dung HTML trong thân phản hồi.\n",
    "\n",
    "#### Yêu cầu POST:\n",
    "Khác với GET, yêu cầu POST gửi dữ liệu trong phần thân yêu cầu (request body) thay vì trong URL. Để thực hiện yêu cầu POST, bạn thay đổi endpoint và sử dụng phương thức `post()` như sau:\n",
    "```python\n",
    "payload = {'name': 'Joseph', 'ID': '123'}\n",
    "response = requests.post('https://httpbin.org/post', data=payload)\n",
    "print(response.text)\n",
    "```\n",
    "- Kết quả của POST không chứa các cặp tên-giá trị trong URL, mà chúng được gửi trong phần thân yêu cầu.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Chúng ta sẽ tìm hiểu về Web Scraping. Sau khi xem xong, bạn sẽ có thể:\n",
    "\n",
    "- Định nghĩa khái niệm web scraping;\n",
    "- Hiểu vai trò của các đối tượng BeautifulSoup;\n",
    "- Áp dụng phương thức `find_all`;\n",
    "- Thực hiện web scraping trên một trang web.\n",
    "\n",
    "#### Web Scraping là gì?\n",
    "Web scraping là quá trình tự động trích xuất thông tin từ một trang web. Thay vì tốn hàng giờ để sao chép thủ công, bạn có thể hoàn thành công việc trong vài phút với một chút mã Python và sự trợ giúp từ hai module: Requests và BeautifulSoup.\n",
    "\n",
    "#### Ví dụ:\n",
    "Giả sử bạn cần tìm tên và lương của các cầu thủ trong Giải bóng rổ quốc gia từ một trang web.  \n",
    "1. **Nhập BeautifulSoup**:  \n",
    "   ```python\n",
    "   from bs4 import BeautifulSoup\n",
    "   ```\n",
    "2. **Phân tích HTML**:  \n",
    "   Lưu HTML của trang web dưới dạng chuỗi và sử dụng BeautifulSoup để phân tích:\n",
    "   ```python\n",
    "   soup = BeautifulSoup(HTML, 'html.parser')\n",
    "   ```\n",
    "\n",
    "#### Phân tích cấu trúc:\n",
    "BeautifulSoup đại diện cho HTML dưới dạng các đối tượng cây (Tree-like objects).  \n",
    "- Ví dụ: Để truy cập thẻ `<title>`, bạn có thể sử dụng:\n",
    "  ```python\n",
    "  title = soup.title\n",
    "  ```\n",
    "\n",
    "#### Áp dụng `find_all`:\n",
    "Phương thức `find_all` lọc và trả về tất cả các thẻ phù hợp:\n",
    "- Ví dụ: Lấy tất cả các hàng trong bảng HTML:\n",
    "  ```python\n",
    "  rows = soup.find_all('tr')\n",
    "  for row in rows:\n",
    "      cells = row.find_all('td')\n",
    "      for cell in cells:\n",
    "          print(cell.text)\n",
    "  ```\n",
    "\n",
    "#### Kết hợp với Requests:\n",
    "Để lấy dữ liệu HTML từ một trang web:\n",
    "```python\n",
    "import requests\n",
    "response = requests.get('https://example.com')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "```\n",
    "Sau đó, bạn có thể sử dụng BeautifulSoup để duyệt và trích xuất thông tin từ trang HTML đó. Hãy thử thực hành trong các bài lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECTIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sau khi hoàn thành phòng thí nghiệm này, bạn sẽ có thể:\n",
    "\n",
    "- Sử dụng các thư viện **requests** và **BeautifulSoup** để trích xuất nội dung của một trang web.\n",
    "- Phân tích mã HTML của một trang web để tìm thông tin liên quan.\n",
    "- Trích xuất thông tin liên quan và lưu nó theo định dạng yêu cầu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCENARIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy giả sử rằng bạn đã được một tổ chức quản lý rạp chiếu phim thuê để trích xuất thông tin về 50 bộ phim có đánh giá trung bình tốt nhất từ liên kết web được chia sẻ dưới đây:\n",
    "\n",
    "[https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films](https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films)\n",
    "\n",
    "Thông tin yêu cầu bao gồm:\n",
    "- **Xếp hạng trung bình (Average Rank)**\n",
    "- **Tên phim (Film)**\n",
    "- **Năm sản xuất (Year)**\n",
    "\n",
    "Bạn cần viết một script Python có tên là `webscraping_movies.py` để trích xuất thông tin này và lưu nó vào một tệp CSV có tên `top_50_films.csv`. Đồng thời, bạn cũng cần lưu cùng thông tin đó vào cơ sở dữ liệu SQLite có tên là `Movies.db`, trong bảng dữ liệu có tên là `Top_50`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pandas as pd \n",
    "import requests\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Khởi tạo các thực thể đã biết\n",
    "Bạn cần khai báo một số thực thể ngay từ đầu. Ví dụ:\n",
    "- URL cần thiết\n",
    "- Tên tệp CSV để lưu bản ghi\n",
    "- Tên cơ sở dữ liệu và tên bảng để lưu trữ bản ghi\n",
    "- Các thực thể cần được lưu trữ\n",
    "\n",
    "Ngoài ra, vì bạn chỉ cần lấy 50 kết quả đầu tiên, bạn sẽ cần một biến đếm vòng lặp được khởi tạo bằng `0`. Bạn có thể khởi tạo tất cả những điều này bằng đoạn mã sau trong tệp `webscraping_movies.py`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url trang web\n",
    "url = \"https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films\"\n",
    "\n",
    "# dia chi tep csv luu ban ghi\n",
    "csv_path = r\"D:\\IBM-Data-Engineering-Python-Project-for-Data-Engineering\\Web-Scraping\\top_50_films.csv\"\n",
    "\n",
    "# ten co so du lieu de luu ban ghi\n",
    "db_name = \"Movies.db\"\n",
    "\n",
    "# ten bang de luu ban ghi\n",
    "table_name = \"Top_50\"\n",
    "\n",
    "# khoi tao dataframe\n",
    "df = pd.DataFrame(columns=[\"Average Rank\", \"Film\", \"Year\"])\n",
    "count = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tải trang web để Web Scraping\n",
    "Để truy cập thông tin cần thiết từ trang web, trước tiên bạn cần tải toàn bộ trang web dưới dạng tài liệu HTML trong Python bằng cách sử dụng hàm `requests.get().text`. Sau đó, phân tích cú pháp văn bản này dưới định dạng HTML bằng **BeautifulSoup** để có thể trích xuất thông tin liên quan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tai trang web duoi dang tai lieu HTML\n",
    "html_page = requests.get(url).text\n",
    "#su dung thu vien BeautifulSoup de phan tich HTML\n",
    "data = BeautifulSoup(html_page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trích xuất thông tin cần thiết\n",
    "Để trích xuất thông tin phù hợp từ trang web, bạn cần viết vòng lặp để duyệt qua các hàng của bảng dữ liệu. Các hàng của bảng có thể được truy cập bằng cách sử dụng hàm `find_all()` với đối tượng **BeautifulSoup** như sau:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lay tat cac doi tuong duoc luu tru bang the 'tbody'\n",
    "tables = data.find_all('tbody')\n",
    "\n",
    "#Inspect web thay bang luu tru cac bo phim nam o the 'tbody' dau tien \n",
    "# Cac hang trong bang duoc luu tru bang the 'tr'\n",
    "rows = tables[0].find_all('tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chức năng của đoạn mã như sau:\n",
    "\n",
    "1. **Duyệt qua nội dung của biến `rows`**:\n",
    "   - Lặp qua từng hàng trong bảng đã lấy được.\n",
    "\n",
    "2. **Kiểm tra biến đếm vòng lặp để giới hạn 50 mục nhập**:\n",
    "   - Đảm bảo chỉ trích xuất 50 hàng đầu tiên.\n",
    "\n",
    "3. **Trích xuất tất cả các đối tượng dữ liệu `<td>` trong hàng và lưu chúng vào biến `col`**:\n",
    "   - Lấy dữ liệu từ các cột trong hàng hiện tại.\n",
    "\n",
    "4. **Kiểm tra độ dài của `col`**:\n",
    "   - Nếu độ dài của `col` là 0 (không có dữ liệu trong hàng hiện tại), bỏ qua hàng đó.\n",
    "   - Điều này rất quan trọng vì đôi khi có những hàng được hợp nhất (merged rows) không hiển thị rõ ràng trên giao diện trang web.\n",
    "\n",
    "5. **Tạo một từ điển `data_dict`**:\n",
    "   - Từ điển này có các khóa trùng với các cột của DataFrame được tạo để lưu trữ đầu ra trước đó.\n",
    "   - Giá trị của các khóa được lấy từ ba cột đầu tiên trong dữ liệu.\n",
    "\n",
    "6. **Chuyển đổi từ điển thành DataFrame và nối nó vào DataFrame hiện có**:\n",
    "   - Cách này giúp dữ liệu được thêm dần vào DataFrame trong mỗi lần lặp.\n",
    "\n",
    "7. **Tăng giá trị của biến đếm vòng lặp**:\n",
    "   - Cập nhật biến đếm để theo dõi số hàng đã xử lý.\n",
    "\n",
    "8. **Dừng lặp khi biến đếm đạt đến 50**:\n",
    "   - Khi đã trích xuất đủ 50 hàng, ngừng vòng lặp và thoát.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average Rank                                           Film  Year\n",
      "0             1                                  The Godfather  1972\n",
      "1             2                                   Citizen Kane  1941\n",
      "2             3                                     Casablanca  1942\n",
      "3             4                         The Godfather, Part II  1974\n",
      "4             5                            Singin' in the Rain  1952\n",
      "5             6                                         Psycho  1960\n",
      "6             7                                    Rear Window  1954\n",
      "7             8                                 Apocalypse Now  1979\n",
      "8             9                          2001: A Space Odyssey  1968\n",
      "9            10                                  Seven Samurai  1954\n",
      "10           11                                        Vertigo  1958\n",
      "11           12                                    Sunset Blvd  1950\n",
      "12           13                                   Modern Times  1936\n",
      "13           14                             Lawrence of Arabia  1962\n",
      "14           15                             North by Northwest  1959\n",
      "15           16                                      Star Wars  1977\n",
      "16           17                                       Parasite  2019\n",
      "17           18                               Schindler's List  1993\n",
      "18           19  Lord of the Rings: The Fellowship of the Ring  2001\n",
      "19           20                           Shawshank Redemption  1994\n",
      "20           21                          It's a Wonderful Life  1946\n",
      "21           22                                   Pulp Fiction  1994\n",
      "22           23                              Avengers: Endgame  2019\n",
      "23           24                                    City Lights  1931\n",
      "24           25                One Flew Over the Cuckoo's Nest  1975\n",
      "25           26                                     Goodfellas  1990\n",
      "26           27                        Raiders of the Lost Ark  1981\n",
      "27           28                                   12 Angry Men  1957\n",
      "28           29                       The Silence of the Lambs  1991\n",
      "29           30                                    Taxi Driver  1976\n",
      "30           31                            Saving Private Ryan  1998\n",
      "31           32                     E.T. the Extra Terrestrial  1982\n",
      "32           33                                          Alien  1979\n",
      "33           34              Spider-Man: Into the Spider-verse  2018\n",
      "34           35                                   Blade Runner  1982\n",
      "35           36                               Double Indemnity  1944\n",
      "36           37                                The Dark Knight  2008\n",
      "37           38                               The Wizard of Oz  1939\n",
      "38           39  Star Wars: Episode V- The Empire Strikes Back  1980\n",
      "39           40                                  The Searchers  1956\n",
      "40           41                             Mad Max: Fury Road  2015\n",
      "41           42                                      Inception  2010\n",
      "42           43          Lord of the Rings: Return of the King  2003\n",
      "43           44                                     The Matrix  1999\n",
      "44           45                                     Fight Club  1999\n",
      "45           46                             Back to the Future  1985\n",
      "46           47                          It Happened One Night  1934\n",
      "47           48                The Good, the Bad, and the Ugly  1966\n",
      "48           49              Lord of the Rings: The Two Towers  2002\n",
      "49           50                                  All About Eve  1950\n"
     ]
    }
   ],
   "source": [
    "#duyet qua tat ca cac the 'td' de lay thong tin ve bo phim\n",
    "# the 'th' chi chua cac truong tieu de nhu Average Rank, Film, Year\n",
    "for row in rows:\n",
    "    if count<50:\n",
    "        col = row.find_all('td')\n",
    "        if len(col)!=0:\n",
    "            data_dict = {\"Average Rank\": col[0].contents[0],\n",
    "                         \"Film\": col[1].contents[0],\n",
    "                         \"Year\": col[2].contents[0]}\n",
    "            df1 = pd.DataFrame(data_dict, index=[0]) #khoi tao df1 la dataframe chua 1 ban ghi, index = [0] de xac dinh rang df1 chi co 1 ban ghi\n",
    "            df = pd.concat([df,df1], ignore_index=True)\n",
    "            count+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STORING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để lưu trữ dữ liệu cần thiết vào cơ sở dữ liệu, trước tiên bạn cần khởi tạo kết nối tới cơ sở dữ liệu, lưu dataframe dưới dạng một bảng, sau đó đóng kết nối"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ý nghĩa các tham số trong câu lệnh to_sql\n",
    "\n",
    "- **`name`**: Tên bảng trong cơ sở dữ liệu.\n",
    "  - Đây là tên bảng mà dữ liệu từ DataFrame sẽ được lưu vào.\n",
    "  - Trong đoạn mã của bạn, `table_name` là tên của bảng đó.\n",
    "\n",
    "- **`con`**: Kết nối cơ sở dữ liệu.\n",
    "  - Là đối tượng kết nối tới cơ sở dữ liệu, trong trường hợp này là `conn` (kết nối SQLite được tạo bằng `sqlite3.connect`).\n",
    "\n",
    "- **`if_exists`**: Xử lý nếu bảng đã tồn tại trong cơ sở dữ liệu.\n",
    "  - Có các tùy chọn:\n",
    "    - `'fail'`: Mặc định, sẽ tạo lỗi nếu bảng đã tồn tại.\n",
    "    - `'replace'`: Xóa bảng cũ (nếu có) và tạo bảng mới, sau đó lưu dữ liệu vào bảng này.\n",
    "    - `'append'`: Thêm dữ liệu mới vào bảng hiện có, không thay thế bảng.\n",
    "- **`index`**: Chỉ định có lưu cột index của DataFrame vào bảng hay không.\n",
    "\n",
    "  - `'index=True'`, cột index của DataFrame sẽ được lưu như một cột trong bảng.\n",
    "  - `'index=False'`, index của DataFrame sẽ bị bỏ qua khi lưu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# khoi tao ket noi toi co so du lieu\n",
    "conn = sqlite3.connect(db_name)\n",
    "\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập thực hành\n",
    "\n",
    "Hãy thử các bài tập thực hành sau để kiểm tra hiểu biết của bạn về nội dung đã học trong bài. Lưu ý rằng lời giải cho các bài tập sau **sẽ không được chia sẻ**. Bạn được khuyến khích tham gia các diễn đàn thảo luận nếu cần hỗ trợ.\n",
    "\n",
    "1. Chỉnh sửa mã để trích xuất các cột **Film**, **Year**, và **Rotten Tomatoes' Top 100**.\n",
    "\n",
    "2. Giới hạn kết quả chỉ bao gồm **25 mục đầu tiên**.\n",
    "\n",
    "3. Lọc đầu ra để chỉ in các bộ phim được phát hành trong thập kỷ 2000 (bao gồm năm 2000).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
