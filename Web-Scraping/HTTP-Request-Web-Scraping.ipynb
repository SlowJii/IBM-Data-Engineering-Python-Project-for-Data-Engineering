{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Chúng ta sẽ thảo luận về giao thức HTTP sử dụng thư viện Requests, một phương pháp phổ biến để xử lý giao thức HTTP trong Python. Chúng ta sẽ xem xét:\n",
    "\n",
    "- Tổng quan về thư viện Requests của Python để làm việc với giao thức HTTP.\n",
    "- Giới thiệu về các yêu cầu GET và POST.\n",
    "\n",
    "#### Thư viện Requests:\n",
    "Requests là một thư viện Python cho phép bạn dễ dàng gửi các yêu cầu HTTP/1.1. Bạn có thể import thư viện như sau:\n",
    "```python\n",
    "import requests\n",
    "```\n",
    "\n",
    "#### Ví dụ về yêu cầu GET:\n",
    "Bạn có thể thực hiện một yêu cầu GET đến `www.ibm.com` như sau:\n",
    "```python\n",
    "response = requests.get('https://www.ibm.com')\n",
    "print(response.status_code)  # In ra mã trạng thái (200 cho OK)\n",
    "```\n",
    "- Sử dụng `response.headers` để xem tiêu đề phản hồi.\n",
    "- Sử dụng `response.text` để hiển thị nội dung HTML trong thân phản hồi.\n",
    "\n",
    "#### Yêu cầu POST:\n",
    "Khác với GET, yêu cầu POST gửi dữ liệu trong phần thân yêu cầu (request body) thay vì trong URL. Để thực hiện yêu cầu POST, bạn thay đổi endpoint và sử dụng phương thức `post()` như sau:\n",
    "```python\n",
    "payload = {'name': 'Joseph', 'ID': '123'}\n",
    "response = requests.post('https://httpbin.org/post', data=payload)\n",
    "print(response.text)\n",
    "```\n",
    "- Kết quả của POST không chứa các cặp tên-giá trị trong URL, mà chúng được gửi trong phần thân yêu cầu.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Chúng ta sẽ tìm hiểu về Web Scraping. Sau khi xem xong, bạn sẽ có thể:\n",
    "\n",
    "- Định nghĩa khái niệm web scraping;\n",
    "- Hiểu vai trò của các đối tượng BeautifulSoup;\n",
    "- Áp dụng phương thức `find_all`;\n",
    "- Thực hiện web scraping trên một trang web.\n",
    "\n",
    "#### Web Scraping là gì?\n",
    "Web scraping là quá trình tự động trích xuất thông tin từ một trang web. Thay vì tốn hàng giờ để sao chép thủ công, bạn có thể hoàn thành công việc trong vài phút với một chút mã Python và sự trợ giúp từ hai module: Requests và BeautifulSoup.\n",
    "\n",
    "#### Ví dụ:\n",
    "Giả sử bạn cần tìm tên và lương của các cầu thủ trong Giải bóng rổ quốc gia từ một trang web.  \n",
    "1. **Nhập BeautifulSoup**:  \n",
    "   ```python\n",
    "   from bs4 import BeautifulSoup\n",
    "   ```\n",
    "2. **Phân tích HTML**:  \n",
    "   Lưu HTML của trang web dưới dạng chuỗi và sử dụng BeautifulSoup để phân tích:\n",
    "   ```python\n",
    "   soup = BeautifulSoup(HTML, 'html.parser')\n",
    "   ```\n",
    "\n",
    "#### Phân tích cấu trúc:\n",
    "BeautifulSoup đại diện cho HTML dưới dạng các đối tượng cây (Tree-like objects).  \n",
    "- Ví dụ: Để truy cập thẻ `<title>`, bạn có thể sử dụng:\n",
    "  ```python\n",
    "  title = soup.title\n",
    "  ```\n",
    "\n",
    "#### Áp dụng `find_all`:\n",
    "Phương thức `find_all` lọc và trả về tất cả các thẻ phù hợp:\n",
    "- Ví dụ: Lấy tất cả các hàng trong bảng HTML:\n",
    "  ```python\n",
    "  rows = soup.find_all('tr')\n",
    "  for row in rows:\n",
    "      cells = row.find_all('td')\n",
    "      for cell in cells:\n",
    "          print(cell.text)\n",
    "  ```\n",
    "\n",
    "#### Kết hợp với Requests:\n",
    "Để lấy dữ liệu HTML từ một trang web:\n",
    "```python\n",
    "import requests\n",
    "response = requests.get('https://example.com')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "```\n",
    "Sau đó, bạn có thể sử dụng BeautifulSoup để duyệt và trích xuất thông tin từ trang HTML đó. Hãy thử thực hành trong các bài lab."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
