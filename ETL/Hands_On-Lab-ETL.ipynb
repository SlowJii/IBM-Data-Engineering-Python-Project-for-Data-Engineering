{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lưu ý quan trọng\n",
    "\n",
    "- **Import ElementTree**:  \n",
    "  Lưu ý rằng bạn chỉ import hàm `ElementTree` từ thư viện `xml.etree` vì bạn cần hàm này để phân tích dữ liệu từ tệp có định dạng XML.\n",
    "\n",
    "- **Đường dẫn tệp (File Paths)**:  \n",
    "  Bạn cũng cần hai đường dẫn tệp được khai báo toàn cục (globally) trong mã nguồn để sử dụng cho tất cả các hàm:\n",
    "  1. **`transformed_data.csv`**: Để lưu trữ dữ liệu đầu ra cuối cùng có thể tải lên cơ sở dữ liệu.\n",
    "  2. **`log_file.txt`**: Để lưu trữ tất cả các bản ghi (logs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"log_file.txt\"\n",
    "target_file = \"transformed_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phát triển các hàm trích xuất\n",
    "\n",
    "- **Mục đích**:  \n",
    "  Tiếp theo, bạn sẽ phát triển các hàm để trích xuất dữ liệu từ các định dạng tệp khác nhau. Vì mỗi định dạng tệp sẽ yêu cầu một hàm riêng, bạn cần viết một hàm cho từng loại: `.csv`, `.json` và `.xml`.\n",
    "\n",
    "- **Tên hàm**:  \n",
    "  Bạn có thể đặt tên cho ba hàm này như sau:\n",
    "  1. **`extract_from_csv()`**\n",
    "  2. **`extract_from_json()`**\n",
    "  3. **`extract_from_xml()`**\n",
    "\n",
    "- **Tham số (Parameters)**:  \n",
    "  Mỗi hàm sẽ nhận một tham số đầu vào là tệp dữ liệu, được đặt tên là `file_to_process`.\n",
    "\n",
    "- **Trích xuất từ CSV**:  \n",
    "  Để trích xuất dữ liệu từ tệp CSV, bạn có thể định nghĩa hàm `extract_from_csv()` như sau bằng cách sử dụng hàm `read_csv` của thư viện pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process): \n",
    "    dataframe = pd.read_csv(file_to_process) \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trích xuất dữ liệu từ tệp JSON\n",
    "\n",
    "- **Trích xuất từ JSON**:  \n",
    "  Để trích xuất dữ liệu từ tệp JSON, bạn có thể định nghĩa hàm `extract_from_json()` bằng cách sử dụng hàm `read_json` của thư viện pandas.\n",
    "\n",
    "- **Tham số bổ sung**:  \n",
    "  Hàm yêu cầu một tham số bổ sung, `lines=True`, để cho phép đọc tệp như một đối tượng JSON theo từng dòng.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process): \n",
    "    dataframe = pd.read_json(file_to_process, lines=True) \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trích xuất dữ liệu từ tệp XML\n",
    "\n",
    "- **Trích xuất từ XML**:  \n",
    "  Để trích xuất dữ liệu từ tệp XML, bạn cần phân tích dữ liệu trước bằng cách sử dụng hàm `ElementTree`. Sau khi dữ liệu được phân tích, bạn có thể trích xuất thông tin cần thiết và thêm chúng vào một DataFrame của pandas.\n",
    "\n",
    "- **Lưu ý**:  \n",
    "  Bạn cần biết các tiêu đề (headers) của dữ liệu được trích xuất để viết hàm này. Trong ví dụ này, các tiêu đề là `\"name\"`, `\"height\"`, và `\"weight\"` đại diện cho thông tin của các cá nhân khác nhau.\n",
    "\n",
    "- **Ví dụ**:  \n",
    "  Quy trình cơ bản:\n",
    "  1. Phân tích tệp XML bằng `ElementTree`.\n",
    "  2. Lặp qua dữ liệu đã phân tích để trích xuất các trường cần thiết.\n",
    "  3. Thêm dữ liệu vào DataFrame của pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process): \n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"]) \n",
    "    tree = ET.parse(file_to_process) \n",
    "    root = tree.getroot() \n",
    "    for person in root: \n",
    "        name = person.find(\"name\").text \n",
    "        height = float(person.find(\"height\").text) \n",
    "        weight = float(person.find(\"weight\").text) \n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True) \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, bạn cần một hàm để xác định hàm nào sẽ được gọi dựa trên loại tệp của tệp dữ liệu. Để gọi hàm phù hợp, hãy viết một hàm `extract`, sử dụng thư viện `glob` để nhận diện loại tệp. Có thể thực hiện điều này như sau:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tham số ignore_index=True đảm bảo các chỉ số (index) được tự động sắp xếp lại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract(): \n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data \n",
    "     \n",
    "    # process all csv files \n",
    "    for csvfile in glob.glob(\"*.csv\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True) \n",
    "         \n",
    "    # process all json files \n",
    "    for jsonfile in glob.glob(\"*.json\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True) \n",
    "     \n",
    "    # process all xml files \n",
    "    for xmlfile in glob.glob(\"*.xml\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True) \n",
    "         \n",
    "    return extracted_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: TRANSFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm Transform: Chuyển đổi đơn vị\n",
    "\n",
    "**Vấn đề**\n",
    "- **Chiều cao** trong dữ liệu trích xuất được đo bằng **inch**, và **cân nặng** được đo bằng **pound**.\n",
    "- Yêu cầu ứng dụng:\n",
    "  - Chiều cao phải được chuyển đổi sang **mét**.\n",
    "  - Cân nặng phải được chuyển đổi sang **kilogram**, làm tròn đến **hai chữ số thập phân**.\n",
    "\n",
    "**Giải pháp**\n",
    "- Viết một hàm có tên là **`transform()`** để thực hiện chuyển đổi đơn vị cho hai tham số này.\n",
    "- Hàm sẽ:\n",
    "  1. Nhận DataFrame đã trích xuất làm đầu vào.\n",
    "  2. Áp dụng chuyển đổi đơn vị cho danh sách chiều cao và cân nặng.\n",
    "\n",
    "**Ghi chú**\n",
    "- DataFrame đầu vào có cấu trúc dạng dictionary với ba khóa:\n",
    "  1. `\"name\"`\n",
    "  2. `\"height\"`\n",
    "  3. `\"weight\"`\n",
    "\n",
    "- Mỗi khóa chứa một danh sách các giá trị, cho phép xử lý toàn bộ danh sách trong một lần.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    data['height'] = round(data.height * 0.0254, 2)\n",
    "    data['weight'] = round(data.weight * 0.453592, 2)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: LOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm Load: Lưu dữ liệu đã chuyển đổi vào tệp CSV\n",
    "\n",
    "**Yêu cầu**\n",
    "- Dữ liệu đã chuyển đổi cần được lưu vào tệp **CSV** để sử dụng cho việc tải lên cơ sở dữ liệu.\n",
    "\n",
    "**Giải pháp**\n",
    "- Viết một hàm có tên là **`load_data()`** để thực hiện việc lưu dữ liệu.\n",
    "- Hàm:\n",
    "  1. Nhận dữ liệu đã chuyển đổi dưới dạng **DataFrame**.\n",
    "  2. Nhận đường dẫn **target_file** nơi dữ liệu sẽ được lưu.\n",
    "  3. Sử dụng thuộc tính `to_csv` của DataFrame để ghi dữ liệu vào tệp được chỉ định."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(target_file, transformed_data):\n",
    "    transformed_data.to_csv(target_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm Logging: Ghi nhận tiến trình của các thao tác\n",
    "\n",
    "**Yêu cầu**\n",
    "- Để theo dõi tiến trình, bạn cần ghi nhận một **thông điệp log** kèm theo **dấu thời gian** vào tệp log (`log_file`).\n",
    "\n",
    "**Giải pháp**\n",
    "- Triển khai một hàm có tên là **`log_progress()`**, với các bước:\n",
    "  1. Nhận thông điệp log làm tham số đầu vào.\n",
    "  2. Lấy **ngày giờ hiện tại** bằng cách sử dụng hàm `datetime` từ thư viện `datetime`.\n",
    "  3. Chuyển đổi dấu thời gian thành chuỗi bằng thuộc tính `strftime` với định dạng ngày-giờ được xác định.\n",
    "  4. Ghi thông điệp kèm dấu thời gian vào tệp log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message): \n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(log_file,\"a\") as f: \n",
    "        f.write(timestamp + ',' + message + '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST ETL OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baoho\\AppData\\Local\\Temp\\ipykernel_20020\\2154094443.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True)\n",
      "C:\\Users\\baoho\\AppData\\Local\\Temp\\ipykernel_20020\\2394561360.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n",
      "C:\\Users\\baoho\\AppData\\Local\\Temp\\ipykernel_20020\\2394561360.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n",
      "C:\\Users\\baoho\\AppData\\Local\\Temp\\ipykernel_20020\\2394561360.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "log_process(\"ETL Job Started\")\n",
    "\n",
    "log_process(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "\n",
    "log_process(\"Extract phase Ended\")\n",
    "\n",
    "log_process(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "log_process(\"Transform phase Ended\")\n",
    "\n",
    "log_process(\"Load phase Started\")\n",
    "load_data(target_file, transformed_data)\n",
    "\n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
